{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image):\n",
    "    cv2.imshow('Imagem', image)\n",
    "    # Aguarda até que uma tecla seja pressionada\n",
    "    cv2.waitKey(0)\n",
    "    # Fecha todas as janelas abertas\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"placa.jpg\")\n",
    "# Exibe a imagem em uma janela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angulo = -13\n",
    "\n",
    "# # Calcula a matriz de rotação\n",
    "# altura, largura = img.shape[:2]\n",
    "# centro = (largura // 2, altura // 2)\n",
    "# matriz = cv2.getRotationMatrix2D(centro, angulo, 1)\n",
    "\n",
    "# # Aplica a rotação na imagem\n",
    "# img = cv2.warpAffine(img, matriz, (largura, altura))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processa a imagem para melhorar a qualidade do OCR (opcional)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "_, gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "showImage(gray)\n",
    "showImage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função createCLAHE é uma parte da biblioteca OpenCV e é usada para a equalização de histograma adaptativa limitada por contraste (CLAHE - Contrast Limited Adaptive Histogram Equalization)1.\n",
    "\n",
    "Ela é usada principalmente para melhorar imagens de baixo contraste. Em vez de aplicar a equalização do histograma em toda a imagem, a CLAHE divide a imagem em pequenos blocos, chamados de “tiles” (normalmente 8x8), e então aplica a equalização do histograma. Isso ajuda a realçar os detalhes locais e reduz o ruído1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aplica a técnica de ajuste de contraste\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = clahe.apply(gray)\n",
    "\n",
    "# Aplica a técnica de remoção de fundo\n",
    "# bgSubtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "# gray = bgSubtractor.apply(gray)\n",
    "showImage(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a técnica de remoção de ruído\n",
    "# kernel = np.ones((3, 3), np.uint8)\n",
    "# gray = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "# showImage(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processa a imagem para melhorar a qualidade do OCR (opcional)\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--psm: Define o modo de segmentação de página. Valores comuns incluem psm 6 para segmentação de blocos de texto e psm 11 para segmentação de linhas de texto 1.\n",
    "--oem: Define o modo de reconhecimento de caracteres. Valores comuns incluem oem 0 para o modo padrão e oem 1 para o modo LSTM 1.\n",
    "--tessdata-dir: Define o diretório que contém os arquivos de treinamento do Tesseract 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OSD significa \"Orientação e Detecção de Script\" em inglês. É um recurso do Tesseract OCR que ajuda a detectar a orientação e o idioma do texto em uma imagem. O OSD é usado para determinar a orientação da imagem (horizontal ou vertical) e o script (alfabeto latino, cirílico, etc.) para ajudar a melhorar a precisão do OCR ¹."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro `--psm` é utilizado para definir o modo de segmentação de página do Tesseract. Existem 14 valores possíveis para esse parâmetro, que são:\n",
    "\n",
    "- `psm 0`: Orientação e detecção de script (OSD) apenas.\n",
    "- `psm 1`: Segmentação automática de página com OSD e reconhecimento de áreas de texto.\n",
    "- `psm 2`: Segmentação automática de página, mas sem OSD ou reconhecimento de áreas de texto.\n",
    "- `psm 3`: Segmentação automática de página, mas sem OSD. Requer um arquivo de configuração.\n",
    "- `psm 4`: Trata a imagem como uma única linha de texto.\n",
    "- `psm 5`: Trata a imagem como uma única palavra.\n",
    "- `psm 6`: Trata a imagem como um único bloco de texto.\n",
    "- `psm 7`: Trata a imagem como uma única palavra em um círculo.\n",
    "- `psm 8`: Trata a imagem como uma única palavra em um círculo com um buraco.\n",
    "- `psm 9`: Trata a imagem como uma única palavra em uma matriz ordenada de caracteres.\n",
    "- `psm 10`: Trata a imagem como um único caractere.\n",
    "- `psm 11`: Segmentação automática de página com OSD e reconhecimento de linhas de texto.\n",
    "- `psm 12`: Segmentação automática de página, mas sem OSD ou reconhecimento de linhas de texto.\n",
    "- `psm 13`: Segmentação automática de página, mas sem OSD. Requer um arquivo de configuração.\n",
    "\n",
    "Cada valor de `--psm` é adequado para diferentes tipos de imagens e situações. É recomendado experimentar diferentes valores de `--psm` para encontrar o melhor valor para cada caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O parâmetro `--oem` é utilizado para definir o modo de reconhecimento de caracteres do Tesseract. Existem quatro valores possíveis para esse parâmetro, que são:\n",
    "\n",
    "- `oem 0`: Modo padrão do Tesseract.\n",
    "- `oem 1`: Modo LSTM (Long Short-Term Memory) do Tesseract.\n",
    "- `oem 2`: Modo Tesseract Cube.\n",
    "- `oem 3`: Modo LSTM com Tesseract Cube.\n",
    "\n",
    "O modo LSTM é uma técnica de aprendizado de máquina que utiliza redes neurais para melhorar a precisão do OCR. O modo Tesseract Cube é um método de reconhecimento de caracteres baseado em dicionário que pode ser mais preciso para certos tipos de imagens ¹.\n",
    "\n",
    "Cada valor de `--oem` é adequado para diferentes tipos de imagens e situações. É recomendado experimentar diferentes valores de `--oem` para encontrar o melhor valor para cada caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/UB-Mannheim/tesseract/wiki\n",
    "pytesseract.pytesseract.tesseract_cmd = \"F:\\Pessoais\\IFCE\\Disciplinas\\PDI\\Aulas\\AulasPraticas\\\\vOCR\\Tesseract_OCR\\Tesseract.exe\"\n",
    "config = r'--oem 1 --psm 11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata?raw=true \n",
    "# result = pytesseract.image_to_string(img, config=config, lang='por')\n",
    "boxes = pytesseract.pytesseract.image_to_boxes(gray, lang='por', config=config)\n",
    "# data = pytesseract.pytesseract.image_to_data(gray, lang='por', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 75 499 108 511 0\n",
      "C 110 498 122 536 0\n",
      "O 123 498 166 511 0\n",
      "B 514 504 538 540 0\n",
      "R 549 504 574 541 0\n",
      "A 581 504 608 541 0\n",
      "S 616 504 635 541 0\n",
      "I 646 504 654 541 0\n",
      "L 667 504 688 541 0\n",
      "( 12 241 15 296 0\n",
      "B 41 239 66 284 0\n",
      "R 68 239 95 284 0\n",
      "B 117 263 224 461 0\n",
      "R 257 262 364 461 0\n",
      "A 397 262 504 461 0\n",
      "Z 539 263 641 461 0\n",
      "E 677 262 784 461 0\n",
      "J 815 262 867 461 0\n",
      "I 820 262 922 461 0\n",
      "9 960 263 1062 461 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:799, W:1200\n",
      "(799, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "imH, imW = gray.shape\n",
    "print(f\"H:{imH}, W:{imW}\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 75 499 108 511 0\n",
      "C 110 498 122 536 0\n",
      "O 123 498 166 511 0\n",
      "B 514 504 538 540 0\n",
      "R 549 504 574 541 0\n",
      "A 581 504 608 541 0\n",
      "S 616 504 635 541 0\n",
      "I 646 504 654 541 0\n",
      "L 667 504 688 541 0\n",
      "( 12 241 15 296 0\n",
      "B 41 239 66 284 0\n",
      "R 68 239 95 284 0\n",
      "B 117 263 224 461 0\n",
      "R 257 262 364 461 0\n",
      "A 397 262 504 461 0\n",
      "Z 539 263 641 461 0\n",
      "E 677 262 784 461 0\n",
      "J 815 262 867 461 0\n",
      "I 820 262 922 461 0\n",
      "9 960 263 1062 461 0\n"
     ]
    }
   ],
   "source": [
    "for i, b in enumerate(boxes.splitlines()):\n",
    "    print(b)\n",
    "    b = b.split(' ')\n",
    "    #print(b)\n",
    "    letra, x, y, w, h = b[0],int(b[1]), int(b[2]),int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x, imH-y), (w, imH-h), (0,255,0), 1)\n",
    "    espacamento = 5\n",
    "    # cv2.putText(img, letra, (x, imH-y+25),  cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 4 )\n",
    "    # Desenha cada letra na imagem com um deslocamento horizontal diferente\n",
    "    x_atual = x + i * espacamento\n",
    "    cv2.putText(img, letra, (x_atual, imH-y+25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
